{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from utils import *\n",
    "import os\n",
    "import pickle\n",
    "from cifar10_input import *\n",
    "from cifar10_models import *\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "#### SET THIS BEFORE RUNNING\n",
    "MODEL_NAME = \"cifar10/cifar10_scm_001\"\n",
    "DISCRIMINATOR_NAME = \"cifar10/cifar10_scm_001_discriminator_wdropout\"\n",
    "try:\n",
    "    os.makedirs(CHECKPOINT.format(MODEL_NAME))\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "class BundledData(InitializableMixin):\n",
    "    def __init__(self, train_in, train_out, test_in, test_out):\n",
    "        with tf.name_scope(\"data_splitter\"):\n",
    "            self.use_test_data = tf.Variable(0, name=\"input_test_vs_train\", trainable=False)\n",
    "            use_test_data = tf.cast(self.use_test_data, tf.bool)\n",
    "            self.input = tf.cond(use_test_data, lambda: test_in, lambda: train_in)\n",
    "            self.input.set_shape(test_in.shape)\n",
    "            self.output = tf.cond(use_test_data, lambda: test_out, lambda: train_out)\n",
    "            self.output.set_shape(test_out.shape)\n",
    "           \n",
    "        \n",
    "tf.reset_default_graph()\n",
    "train_files, test_files = maybe_download_and_extract()\n",
    "train_data = Cifar10Record(train_files)\n",
    "test_data = Cifar10Record(test_files)\n",
    "data = BundledData(train_data.image, train_data.label, test_data.image, test_data.label)\n",
    "\n",
    "model = Cifar10ShallowConvolutionalModel(data.input, data.output, trainable=False)\n",
    "model = Cifar10ShallowConvolutionalModel(data.input, data.output, trainable=False)\n",
    "\n",
    "try:\n",
    "    checkpoints = sorted([\"{}/{}\".format(ROOT.format(MODEL_NAME),x[:-5]) for x in os.listdir(ROOT.format(MODEL_NAME)) if x.endswith(\".meta\")], \n",
    "                     key=lambda x: int(x.split(\"-\")[-1]))\n",
    "except FileNotFoundError:\n",
    "    checkpoints = []\n",
    "model.saver.recover_last_checkpoints(checkpoints)\n",
    "try: latest_checkpoint = model.saver.last_checkpoints[-4]\n",
    "except: latest_checkpoint = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(TrainableMixin):\n",
    "    def __init__(self, model, batch_size, summaries=True): \n",
    "        self.model = model\n",
    "        self.batch_size = batch_size\n",
    "        self._init_graph(summaries)\n",
    "        self._init_saver()\n",
    "\n",
    "    def _init_graph(self, summaries=True):\n",
    "        with tf.name_scope(\"discriminator\"):\n",
    "            \n",
    "            with tf.name_scope(\"meta_variables\"):\n",
    "                self.global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "                self.learning_rate = tf.Variable(0.001, name=\"learning_rate\", trainable=False)\n",
    "\n",
    "            with tf.name_scope(\"layer_000_input\"):\n",
    "                self.input_dim = list(np.multiply(2, self.model.output_dim))\n",
    "                self.output_dim = [2]\n",
    "                self.use_test_data = tf.Variable(1, trainable=False)\n",
    "                self.y_ = tf.one_hot(self.use_test_data, 2, on_value=1.0, off_value=0.0)\n",
    "                self.y_ = tf.reshape(self.y_, [1] + self.output_dim)\n",
    "                self.y_ = tf.tile(self.y_,[self.batch_size,1])\n",
    "                self.x = tf.concat((self.model.proba, self.model.y_),1)\n",
    "                layer_000_out_dim = self.input_dim\n",
    "                \n",
    "            with tf.name_scope(\"layer_001_fc\"):\n",
    "                layer_001_in_dim = layer_000_out_dim\n",
    "                layer_001_out_dim = [100]\n",
    "                self.W_001 = tf.Variable(tf.random_normal(layer_001_in_dim + layer_001_out_dim,0,0.1), name=\"weights\")\n",
    "                self.b_001 = tf.Variable(tf.random_normal(layer_001_out_dim,0,0.1), name=\"bias\")\n",
    "                self.logits_001 = tf.add(tf.matmul(self.x,self.W_001, name=\"mul_weights\"), self.b_001, name=\"add_bias\")\n",
    "                self.bent_001 = tf.nn.relu(self.logits_001, name=\"relu\")\n",
    "                self.dropout_rate_001 = tf.Variable(2.0, name=\"dropout_rate\", trainable=False)\n",
    "                self.dropout_001 = tf.nn.dropout(self.bent_001, 1-self.dropout_rate_001, name=\"dropout\")\n",
    "                \n",
    "            with tf.name_scope(\"layer_002_fc\"):\n",
    "                layer_002_in_dim = layer_001_out_dim\n",
    "                layer_002_out_dim = [10]\n",
    "                self.W_002 = tf.Variable(tf.random_normal(layer_002_in_dim + layer_002_out_dim,0,0.1), name=\"weights\")\n",
    "                self.b_002 = tf.Variable(tf.random_normal(layer_002_out_dim,0,0.1), name=\"bias\")\n",
    "                self.logits_002 = tf.add(tf.matmul(self.dropout_001,self.W_002, name=\"mul_weights\"), self.b_002, name=\"add_bias\")\n",
    "                self.bent_002 = tf.nn.relu(self.logits_002, name=\"relu\")\n",
    "                self.dropout_rate_002 = tf.Variable(1.0, name=\"dropout_rate\", trainable=False)\n",
    "                self.dropout_002 = tf.nn.dropout(self.bent_002, 1-self.dropout_rate_002, name=\"dropout\")\n",
    "\n",
    "            with tf.name_scope(\"layer_003_fc\"):\n",
    "                layer_003_in_dim = layer_002_out_dim\n",
    "                layer_003_out_dim = self.output_dim\n",
    "                self.W_003 = tf.Variable(tf.random_normal(layer_003_in_dim + layer_003_out_dim,0,0.1), name=\"weights\")\n",
    "                self.b_003 = tf.Variable(tf.random_normal(layer_003_out_dim,0,0.1), name=\"bias\")\n",
    "                self.logits_003 = tf.add(tf.matmul(self.dropout_002,self.W_003, name=\"mul_weights\"), self.b_003, name=\"add_bias\")\n",
    "                \n",
    "            with tf.name_scope(\"outputs\"):\n",
    "                self.logits = self.logits_003\n",
    "                self.proba = tf.nn.softmax(self.logits)\n",
    "                self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=self.y_, logits=self.logits))\n",
    "                \n",
    "            with tf.name_scope(\"summaries\"):\n",
    "                self.correct_prediction = tf.equal(tf.argmax(self.logits,1), tf.argmax(self.y_,1))\n",
    "                self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32), name=\"accuracy\")\n",
    "                self.summaries = {}\n",
    "                if summaries:\n",
    "                    self.summaries = {\n",
    "                        \"batch acc.\": tf.summary.scalar(\"batch_acc\", self.accuracy)\n",
    "                    }\n",
    "\n",
    "            with tf.name_scope(\"training\"): \n",
    "                self.optimizer = tf.train.GradientDescentOptimizer(self.learning_rate, name=\"optimizer\")\n",
    "                self.grads = self.optimizer.compute_gradients(self.loss)\n",
    "                self.grad_application = self.optimizer.apply_gradients(self.grads, global_step = self.global_step)\n",
    "                with tf.control_dependencies([self.grad_application] + list(self.summaries.values())):\n",
    "                    self.train_step = tf.no_op(name=\"train_step\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator(model, 100)\n",
    "\n",
    "try:\n",
    "    discriminator_checkpoints = sorted([\"{}/{}\".format(ROOT.format(DISCRIMINATOR_NAME),x[:-5]) for x in os.listdir(ROOT.format(DISCRIMINATOR_NAME)) if x.endswith(\".meta\")], \n",
    "                     key=lambda x: int(x.split(\"-\")[-1]))\n",
    "except FileNotFoundError:\n",
    "    discriminator_checkpoints = []\n",
    "discriminator.saver.recover_last_checkpoints(discriminator_checkpoints)\n",
    "try: discriminator_latest_checkpoint = discriminator.saver.last_checkpoints[-13]\n",
    "except: discriminator_latest_checkpoint = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-500',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-1000',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-1500',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-2000',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-2500',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-3000',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-3500',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-4000',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-4500',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-5000',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-5500',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-6000',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-6500',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-7000',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-7500',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-8000',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-8500',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-9000',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-9500',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-10000',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-10500',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-11000',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-11500',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-12000',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-12500',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-13000',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-13500',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-14000',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-14500',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-15000',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-15500',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-16000',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-16500',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-17000',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-17500',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-18000',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-18500',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-19000',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-19500',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-20000',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-20500',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-21000',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-21500',\n",
       " '../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-22000']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../models/cifar10/cifar10_scm_001/model.ckpt-358500\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_500\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-500 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_1000\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-1000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_1500\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-1500 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_2000\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-2000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_2500\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-2500 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_3000\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-3000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_3500\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-3500 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_4000\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-4000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_4500\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-4500 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_5000\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-5000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_5500\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-5500 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_6000\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-6000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_6500\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-6500 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_7000\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-7000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_7500\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-7500 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_8000\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-8000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_8500\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-8500 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_9000\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-9000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_9500\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-9500 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_10000\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-10000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_10500\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-10500 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_11000\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-11000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_11500\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-11500 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_12000\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-12000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_12500\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-12500 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_13000\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-13000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_13500\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-13500 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_14000\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-14000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_14500\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-14500 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_15000\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-15000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_15500\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-15500 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_16000\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-16000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_16500\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-16500 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_17000\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-17000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_17500\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-17500 is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_18000\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-18000 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Saving to:  ../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt_18500\n",
      "INFO:tensorflow:../models/cifar10/cifar10_scm_001_discriminator_wdropout/model.ckpt-18500 is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "save_rate = 500\n",
    "with tf.Session() as sess:\n",
    "    model._restore_or_init(sess, latest_checkpoint)\n",
    "    data._initialize(sess)\n",
    "    discriminator._restore_or_init(sess, None)\n",
    "    tf.assign(discriminator.dropout_rate_002, 0.5)\n",
    "    tf.assign(discriminator.dropout_rate_001, 0.5)\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            sess.run(discriminator.train_step)\n",
    "            global_step = discriminator.global_step.eval()\n",
    "            use_test_data = global_step%2\n",
    "            data.use_test_data.assign(use_test_data)\n",
    "            discriminator.use_test_data.assign(use_test_data)\n",
    "            if not global_step%save_rate:\n",
    "                print(\"Saving to: \", CHECKPOINT.format(DISCRIMINATOR_NAME) + \"_\" + str(global_step))\n",
    "                discriminator.saver.save(sess, CHECKPOINT.format(DISCRIMINATOR_NAME), global_step=global_step)\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
